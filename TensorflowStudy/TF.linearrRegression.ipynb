{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "helli = tf.constant(\"Hello, Tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow의 구동원리\n",
    "\n",
    "- Tensorflow는 tensor라고하는 데이터(edge)가 operation등이 들어있는 Node를 통해 흐른다고 하여 Tensorflow라고한다. 따라서 Edge와 Node가 있는 Graph로 작동한다.\n",
    "- 따라서 위와같이 tf.constant를 해서 NOde를 만들더라도 단순히 print하여도 원하는 값이 나오지 않고,node의 실행을 위한 Session이 필요하다. \n",
    "- 따라서 먼저 Graph를 구성하고 Session을 통해서 Graph를 실행하는 것이 가장 큰 틀이라고 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow'\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(helli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :  Tensor(\"Const_7:0\", shape=(), dtype=float32) node2 :  Tensor(\"Const_8:0\", shape=(), dtype=float32) node3 :  Tensor(\"Add_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1 : \", node1, \"node2 : \", node2, \"node3 : \", node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(node3) :  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3) : \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict = {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict = {a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis and cost function\n",
    "- H(x) = Wx + b\n",
    "- minimize cost(W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. H(x) = Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "#Variable은 tensorflow가 사용하는 Variable이다\n",
    "#tf.random_normal([1]) rank가 1인(scalar) 랜덤한 숫자를 만든다.\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Our hypothesis XW + b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. cost(W,b) = 1/m*summation(H(x)-y)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.7057 [ 0.86121368] [-1.06557286]\n",
      "20 0.0185142 [ 0.86121368] [-1.06557286]\n",
      "40 0.00293708 [ 0.86121368] [-1.06557286]\n",
      "60 0.00254167 [ 0.86121368] [-1.06557286]\n",
      "80 0.00230724 [ 0.86121368] [-1.06557286]\n",
      "100 0.00209547 [ 0.86121368] [-1.06557286]\n",
      "120 0.00190314 [ 0.86121368] [-1.06557286]\n",
      "140 0.00172846 [ 0.86121368] [-1.06557286]\n",
      "160 0.00156982 [ 0.86121368] [-1.06557286]\n",
      "180 0.00142573 [ 0.86121368] [-1.06557286]\n",
      "200 0.00129487 [ 0.86121368] [-1.06557286]\n",
      "220 0.00117602 [ 0.86121368] [-1.06557286]\n",
      "240 0.00106808 [ 0.86121368] [-1.06557286]\n",
      "260 0.000970043 [ 0.86121368] [-1.06557286]\n",
      "280 0.000881015 [ 0.86121368] [-1.06557286]\n",
      "300 0.000800147 [ 0.86121368] [-1.06557286]\n",
      "320 0.000726707 [ 0.86121368] [-1.06557286]\n",
      "340 0.000660009 [ 0.86121368] [-1.06557286]\n",
      "360 0.00059943 [ 0.86121368] [-1.06557286]\n",
      "380 0.000544411 [ 0.86121368] [-1.06557286]\n",
      "400 0.000494442 [ 0.86121368] [-1.06557286]\n",
      "420 0.000449063 [ 0.86121368] [-1.06557286]\n",
      "440 0.000407845 [ 0.86121368] [-1.06557286]\n",
      "460 0.000370412 [ 0.86121368] [-1.06557286]\n",
      "480 0.000336413 [ 0.86121368] [-1.06557286]\n",
      "500 0.000305538 [ 0.86121368] [-1.06557286]\n",
      "520 0.000277492 [ 0.86121368] [-1.06557286]\n",
      "540 0.000252023 [ 0.86121368] [-1.06557286]\n",
      "560 0.000228892 [ 0.86121368] [-1.06557286]\n",
      "580 0.000207883 [ 0.86121368] [-1.06557286]\n",
      "600 0.000188804 [ 0.86121368] [-1.06557286]\n",
      "620 0.000171475 [ 0.86121368] [-1.06557286]\n",
      "640 0.000155735 [ 0.86121368] [-1.06557286]\n",
      "660 0.000141441 [ 0.86121368] [-1.06557286]\n",
      "680 0.000128457 [ 0.86121368] [-1.06557286]\n",
      "700 0.000116667 [ 0.86121368] [-1.06557286]\n",
      "720 0.000105959 [ 0.86121368] [-1.06557286]\n",
      "740 9.62343e-05 [ 0.86121368] [-1.06557286]\n",
      "760 8.74007e-05 [ 0.86121368] [-1.06557286]\n",
      "780 7.93787e-05 [ 0.86121368] [-1.06557286]\n",
      "800 7.20926e-05 [ 0.86121368] [-1.06557286]\n",
      "820 6.54754e-05 [ 0.86121368] [-1.06557286]\n",
      "840 5.94658e-05 [ 0.86121368] [-1.06557286]\n",
      "860 5.40084e-05 [ 0.86121368] [-1.06557286]\n",
      "880 4.90506e-05 [ 0.86121368] [-1.06557286]\n",
      "900 4.45494e-05 [ 0.86121368] [-1.06557286]\n",
      "920 4.04611e-05 [ 0.86121368] [-1.06557286]\n",
      "940 3.67474e-05 [ 0.86121368] [-1.06557286]\n",
      "960 3.33741e-05 [ 0.86121368] [-1.06557286]\n",
      "980 3.03099e-05 [ 0.86121368] [-1.06557286]\n",
      "1000 2.75285e-05 [ 0.86121368] [-1.06557286]\n",
      "1020 2.50018e-05 [ 0.86121368] [-1.06557286]\n",
      "1040 2.27071e-05 [ 0.86121368] [-1.06557286]\n",
      "1060 2.06237e-05 [ 0.86121368] [-1.06557286]\n",
      "1080 1.87304e-05 [ 0.86121368] [-1.06557286]\n",
      "1100 1.7011e-05 [ 0.86121368] [-1.06557286]\n",
      "1120 1.545e-05 [ 0.86121368] [-1.06557286]\n",
      "1140 1.40317e-05 [ 0.86121368] [-1.06557286]\n",
      "1160 1.27444e-05 [ 0.86121368] [-1.06557286]\n",
      "1180 1.15739e-05 [ 0.86121368] [-1.06557286]\n",
      "1200 1.05123e-05 [ 0.86121368] [-1.06557286]\n",
      "1220 9.54716e-06 [ 0.86121368] [-1.06557286]\n",
      "1240 8.67116e-06 [ 0.86121368] [-1.06557286]\n",
      "1260 7.87513e-06 [ 0.86121368] [-1.06557286]\n",
      "1280 7.15288e-06 [ 0.86121368] [-1.06557286]\n",
      "1300 6.49626e-06 [ 0.86121368] [-1.06557286]\n",
      "1320 5.9e-06 [ 0.86121368] [-1.06557286]\n",
      "1340 5.35839e-06 [ 0.86121368] [-1.06557286]\n",
      "1360 4.86673e-06 [ 0.86121368] [-1.06557286]\n",
      "1380 4.41968e-06 [ 0.86121368] [-1.06557286]\n",
      "1400 4.01437e-06 [ 0.86121368] [-1.06557286]\n",
      "1420 3.64575e-06 [ 0.86121368] [-1.06557286]\n",
      "1440 3.31138e-06 [ 0.86121368] [-1.06557286]\n",
      "1460 3.00746e-06 [ 0.86121368] [-1.06557286]\n",
      "1480 2.73141e-06 [ 0.86121368] [-1.06557286]\n",
      "1500 2.48083e-06 [ 0.86121368] [-1.06557286]\n",
      "1520 2.25339e-06 [ 0.86121368] [-1.06557286]\n",
      "1540 2.04658e-06 [ 0.86121368] [-1.06557286]\n",
      "1560 1.85851e-06 [ 0.86121368] [-1.06557286]\n",
      "1580 1.6879e-06 [ 0.86121368] [-1.06557286]\n",
      "1600 1.53316e-06 [ 0.86121368] [-1.06557286]\n",
      "1620 1.3925e-06 [ 0.86121368] [-1.06557286]\n",
      "1640 1.26479e-06 [ 0.86121368] [-1.06557286]\n",
      "1660 1.14875e-06 [ 0.86121368] [-1.06557286]\n",
      "1680 1.04338e-06 [ 0.86121368] [-1.06557286]\n",
      "1700 9.47821e-07 [ 0.86121368] [-1.06557286]\n",
      "1720 8.60781e-07 [ 0.86121368] [-1.06557286]\n",
      "1740 7.81838e-07 [ 0.86121368] [-1.06557286]\n",
      "1760 7.10245e-07 [ 0.86121368] [-1.06557286]\n",
      "1780 6.45078e-07 [ 0.86121368] [-1.06557286]\n",
      "1800 5.86024e-07 [ 0.86121368] [-1.06557286]\n",
      "1820 5.32195e-07 [ 0.86121368] [-1.06557286]\n",
      "1840 4.83442e-07 [ 0.86121368] [-1.06557286]\n",
      "1860 4.39092e-07 [ 0.86121368] [-1.06557286]\n",
      "1880 3.98843e-07 [ 0.86121368] [-1.06557286]\n",
      "1900 3.6227e-07 [ 0.86121368] [-1.06557286]\n",
      "1920 3.2912e-07 [ 0.86121368] [-1.06557286]\n",
      "1940 2.9904e-07 [ 0.86121368] [-1.06557286]\n",
      "1960 2.71533e-07 [ 0.86121368] [-1.06557286]\n",
      "1980 2.46643e-07 [ 0.86121368] [-1.06557286]\n",
      "2000 2.24092e-07 [ 0.86121368] [-1.06557286]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "#Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#fit the Line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    # 경사 하강법 20회에 한번씩 출력\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16.6515 [ 0.39119714] [-0.07834136]\n",
      "20 0.141075 [ 1.23881233] [ 0.22256142]\n",
      "40 0.122908 [ 1.22682071] [ 0.28103614]\n",
      "60 0.107336 [ 1.21198261] [ 0.33467525]\n",
      "80 0.0937375 [ 1.19809973] [ 0.38479698]\n",
      "100 0.0818617 [ 1.18512607] [ 0.43163612]\n",
      "120 0.0714904 [ 1.173002] [ 0.47540778]\n",
      "140 0.0624331 [ 1.161672] [ 0.51631284]\n",
      "160 0.0545232 [ 1.15108395] [ 0.55453914]\n",
      "180 0.0476156 [ 1.14118934] [ 0.59026182]\n",
      "200 0.041583 [ 1.13194263] [ 0.62364507]\n",
      "220 0.0363148 [ 1.12330151] [ 0.6548419]\n",
      "240 0.0317139 [ 1.11522651] [ 0.68399566]\n",
      "260 0.0276961 [ 1.1076802] [ 0.71124011]\n",
      "280 0.0241871 [ 1.10062814] [ 0.73670024]\n",
      "300 0.0211228 [ 1.09403801] [ 0.76049316]\n",
      "320 0.0184467 [ 1.0878793] [ 0.78272772]\n",
      "340 0.0161096 [ 1.08212399] [ 0.80350614]\n",
      "360 0.0140687 [ 1.07674575] [ 0.82292372]\n",
      "380 0.0122863 [ 1.07171953] [ 0.84106964]\n",
      "400 0.0107297 [ 1.06702256] [ 0.85802722]\n",
      "420 0.00937032 [ 1.06263316] [ 0.87387431]\n",
      "440 0.00818317 [ 1.05853128] [ 0.88868344]\n",
      "460 0.00714641 [ 1.05469799] [ 0.90252274]\n",
      "480 0.00624101 [ 1.05111575] [ 0.91545576]\n",
      "500 0.00545033 [ 1.04776812] [ 0.92754173]\n",
      "520 0.00475982 [ 1.04463983] [ 0.93883616]\n",
      "540 0.00415677 [ 1.04171646] [ 0.94939083]\n",
      "560 0.00363015 [ 1.0389843] [ 0.95925426]\n",
      "580 0.00317023 [ 1.03643107] [ 0.96847194]\n",
      "600 0.00276859 [ 1.03404534] [ 0.97708571]\n",
      "620 0.00241783 [ 1.03181565] [ 0.9851355]\n",
      "640 0.00211151 [ 1.02973199] [ 0.9926579]\n",
      "660 0.00184401 [ 1.02778482] [ 0.99968785]\n",
      "680 0.00161039 [ 1.02596521] [ 1.00625741]\n",
      "700 0.00140635 [ 1.02426469] [ 1.01239669]\n",
      "720 0.00122818 [ 1.02267551] [ 1.01813412]\n",
      "740 0.00107258 [ 1.02119064] [ 1.02349544]\n",
      "760 0.000936697 [ 1.01980281] [ 1.02850556]\n",
      "780 0.000818018 [ 1.01850581] [ 1.03318775]\n",
      "800 0.000714384 [ 1.01729393] [ 1.03756344]\n",
      "820 0.000623881 [ 1.01616132] [ 1.04165244]\n",
      "840 0.000544832 [ 1.01510274] [ 1.04547393]\n",
      "860 0.000475805 [ 1.01411366] [ 1.04904485]\n",
      "880 0.000415525 [ 1.01318944] [ 1.05238199]\n",
      "900 0.000362876 [ 1.01232564] [ 1.05550051]\n",
      "920 0.000316905 [ 1.01151836] [ 1.05841482]\n",
      "940 0.000276758 [ 1.01076412] [ 1.06113815]\n",
      "960 0.0002417 [ 1.01005924] [ 1.06368303]\n",
      "980 0.000211076 [ 1.00940037] [ 1.06606162]\n",
      "1000 0.000184332 [ 1.00878465] [ 1.06828439]\n",
      "1020 0.00016098 [ 1.00820947] [ 1.07036114]\n",
      "1040 0.000140588 [ 1.00767183] [ 1.07230222]\n",
      "1060 0.000122774 [ 1.00716937] [ 1.07411635]\n",
      "1080 0.000107219 [ 1.0066998] [ 1.07581139]\n",
      "1100 9.36368e-05 [ 1.00626111] [ 1.07739532]\n",
      "1120 8.1774e-05 [ 1.00585103] [ 1.07887566]\n",
      "1140 7.14146e-05 [ 1.00546789] [ 1.08025897]\n",
      "1160 6.2365e-05 [ 1.00510979] [ 1.08155191]\n",
      "1180 5.44658e-05 [ 1.00477517] [ 1.0827601]\n",
      "1200 4.7564e-05 [ 1.00446248] [ 1.08388901]\n",
      "1220 4.15391e-05 [ 1.00417018] [ 1.08494401]\n",
      "1240 3.62772e-05 [ 1.00389719] [ 1.08592999]\n",
      "1260 3.16817e-05 [ 1.00364196] [ 1.08685136]\n",
      "1280 2.76678e-05 [ 1.00340343] [ 1.08771253]\n",
      "1300 2.41626e-05 [ 1.0031805] [ 1.08851719]\n",
      "1320 2.1101e-05 [ 1.00297225] [ 1.08926904]\n",
      "1340 1.84306e-05 [ 1.0027777] [ 1.08997118]\n",
      "1360 1.60946e-05 [ 1.0025959] [ 1.09062815]\n",
      "1380 1.40568e-05 [ 1.00242591] [ 1.09124184]\n",
      "1400 1.22754e-05 [ 1.00226688] [ 1.09181535]\n",
      "1420 1.0721e-05 [ 1.00211859] [ 1.09235132]\n",
      "1440 9.36278e-06 [ 1.00197971] [ 1.09285223]\n",
      "1460 8.17579e-06 [ 1.00185013] [ 1.09332037]\n",
      "1480 7.14059e-06 [ 1.00172901] [ 1.09375775]\n",
      "1500 6.23598e-06 [ 1.00161588] [ 1.09416652]\n",
      "1520 5.44645e-06 [ 1.00151002] [ 1.09454846]\n",
      "1540 4.75605e-06 [ 1.00141108] [ 1.0949055]\n",
      "1560 4.15325e-06 [ 1.00131869] [ 1.09523916]\n",
      "1580 3.62742e-06 [ 1.00123239] [ 1.09555089]\n",
      "1600 3.16814e-06 [ 1.00115168] [ 1.09584212]\n",
      "1620 2.76695e-06 [ 1.00107622] [ 1.0961144]\n",
      "1640 2.41588e-06 [ 1.00100577] [ 1.09636879]\n",
      "1660 2.10983e-06 [ 1.00093985] [ 1.09660685]\n",
      "1680 1.84251e-06 [ 1.00087833] [ 1.09682906]\n",
      "1700 1.60901e-06 [ 1.00082088] [ 1.0970366]\n",
      "1720 1.40522e-06 [ 1.00076711] [ 1.09723055]\n",
      "1740 1.22742e-06 [ 1.00071692] [ 1.09741187]\n",
      "1760 1.07213e-06 [ 1.00067008] [ 1.09758127]\n",
      "1780 9.36425e-07 [ 1.00062609] [ 1.09773958]\n",
      "1800 8.17818e-07 [ 1.00058508] [ 1.0978874]\n",
      "1820 7.14233e-07 [ 1.00054681] [ 1.09802568]\n",
      "1840 6.23834e-07 [ 1.00051105] [ 1.09815478]\n",
      "1860 5.44903e-07 [ 1.00047755] [ 1.09827554]\n",
      "1880 4.75905e-07 [ 1.00044632] [ 1.09838843]\n",
      "1900 4.15637e-07 [ 1.00041723] [ 1.09849393]\n",
      "1920 3.63047e-07 [ 1.00039005] [ 1.0985924]\n",
      "1940 3.17085e-07 [ 1.00036442] [ 1.09868443]\n",
      "1960 2.77035e-07 [ 1.00034046] [ 1.09877038]\n",
      "1980 2.41986e-07 [ 1.00031841] [ 1.09885085]\n",
      "2000 2.11317e-07 [ 1.00029743] [ 1.09892607]\n"
     ]
    }
   ],
   "source": [
    "#placeholders를 사용해봅시다\n",
    "#placeholders를 이용하면 먼저 알고리즘을 만들고 나중에 데이터를 집어넣기 용이하다. \n",
    "#Shape = [None]는 몇차원데이터든 상관없다 이경우 2\n",
    "X = tf.placeholder(tf.float32, shape = [None])\n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#Our hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "#cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "#Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.10041332]\n",
      "[ 3.59966969]\n",
      "[ 2.59937215  4.599967  ]\n"
     ]
    }
   ],
   "source": [
    "# testing our model\n",
    "print(sess.run(hypothesis, feed_dict = {X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing Cost\n",
    "- gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179032eea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "W= tf.placeholder(tf.float32)\n",
    "hypothesis = X * W\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "#Launch the graph in the graph\n",
    "sess = tf.Session()\n",
    "#Initialize global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#비용함수 그리기 위한 변수들을 위한 list 생성\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for i in range(-30, 50):\n",
    "    #(-3,5)구간에서 plotting\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "# 비용함수 plotting\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법\n",
    "경사를 이용하기 위해 미분한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W -= Learning_rate * derivative of cost function\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "#tensorflow 에서는 -=를 통해서 업데이트가 안되므로 assigin()이용\n",
    "update = W.assign(descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 48.1542 [ 0.25972909]\n",
      "1 48.1542 [ 0.60518885]\n",
      "2 48.1542 [ 0.78943408]\n",
      "3 48.1542 [ 0.88769817]\n",
      "4 48.1542 [ 0.94010568]\n",
      "5 48.1542 [ 0.96805638]\n",
      "6 48.1542 [ 0.98296338]\n",
      "7 48.1542 [ 0.99091381]\n",
      "8 48.1542 [ 0.99515402]\n",
      "9 48.1542 [ 0.99741548]\n",
      "10 48.1542 [ 0.99862158]\n",
      "11 48.1542 [ 0.99926484]\n",
      "12 48.1542 [ 0.99960792]\n",
      "13 48.1542 [ 0.99979091]\n",
      "14 48.1542 [ 0.99988848]\n",
      "15 48.1542 [ 0.99994051]\n",
      "16 48.1542 [ 0.99996829]\n",
      "17 48.1542 [ 0.99998307]\n",
      "18 48.1542 [ 0.999991]\n",
      "19 48.1542 [ 0.99999517]\n",
      "20 48.1542 [ 0.99999744]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "W= tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "# our Hypothesis for linear model (simplified) X * W\n",
    "hypothesis = X * W\n",
    "# cost/ Loss Function\n",
    "cost = tf.reduce_mean(tf.square(hypthesis - Y))\n",
    "\n",
    "#minimize \n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "#launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# initialize global function variable in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict = {X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow에서의 GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 70.0\n",
      "1 5.6\n",
      "2 1.30667\n",
      "3 1.02044\n",
      "4 1.00136\n",
      "5 1.00009\n",
      "6 1.00001\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "W = tf.Variable(70.0)\n",
    "hypothesis = X * W\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "#tensorflow에서는 메소드로 존재한다. \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "                        \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "                                \n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-a308454ae0f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgvs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapply_gradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kjw1o\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[1;32m--> 230\u001b[1;33m                       (fetch, type(fetch)))\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "#tensorflow 안에서 grdient를 손대고 싶을 떄 사용하는 방법\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(5.)\n",
    "hypothesis = X * W\n",
    "\n",
    "#직접 구한 gradient값\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "\n",
    "#Gradient값을 얻는다.\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "\n",
    "#Gradient 적용\n",
    "apply_gradient = optimizer.apply_gradients(gvs)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
