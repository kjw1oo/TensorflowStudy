{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200830af438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1], [2], [3]],\n",
    "                   [[4], [5], [6]],\n",
    "                   [[7], [8], [9]]]], dtype = np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3, 3), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- image : 1, 3, 3, 1\n",
    "- Filter : 2, 2, 1, 1\n",
    "- Stride : 1 X 1\n",
    "- Padding: Valid\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* image : 1개의 3 X 3 X 1의 이미지 (1,3,3,1) = (이미지갯수, 크기1,크기2, 색깔)\n",
    "* Filter : 2 X 2 X 1 에 1개의 filter를 사용 (2,2,1,1) = (크기1, 크기2,, 색깔, 필터갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[ 12.  16.]\n",
      " [ 24.  28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAC7CAYAAADGxxq1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njg2VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2008319fe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"imag \\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "#Filter\n",
    "weight = tf.constant([[[[1.0]], [[1.0]]],\n",
    "                      [[[1.0]], [[1.0]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(2, 2), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAC7CAYAAADPLLrPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ2KW+D8H4vpp8cqpkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20083348e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"imag \\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "#Filter\n",
    "weight = tf.constant([[[[1.0]], [[1.0]]],\n",
    "                      [[[1.0]], [[1.0]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 여러개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAACFCAYAAAB8MZtGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDVJREFUeJzt3c+LVXUch/Hn3cxVxASFWsQoXQMJ3CU6myCklbVxq4tW\nwayEgjb+Fe1mIyQhRBLUwoUgLpIIIpykwB8YkxAqQWWI7UT4tHAWN4ruEe/5nmvzvGBg7p3LuR+G\nZ879Mfd7TqoKbW7PDT2AhmcEMgIZgTACYQTCCIQRCCMQsNjLRhcXazQa9bHpzrZv3z7o/QPcu3dv\n6BGoqky7TS8RjEYjxuNxH5vubHl5edD7Bzhz5szQI3Tiw4GMQEYgjEAYgTACYQTCCIQRCCMQRiA6\nRpDkSJKbSdaTnOx7KLU1NYIkC8Aq8BawHzieZH/fg6mdLnuCZWC9qm5V1UPgLHC037HUUpcIloDb\nE5fvbFyn/4mZfZ4gyQqwArC42MvHFNSTLnuCu8Ceicu7N677m6o6VVUHq+qgETxbukRwGdiXZG+S\nLcAx4Fy/Y6mlqX+yVfUoyQngArAAnK6qa71PpmY67ber6jxwvudZNBDfMZQRyAiEEQgjEEYgjEAY\ngTACYQTCCERPxycYj8eDr80/dOjQoPcP8ODBg0Hv/9KlS51u555ARiAjEEYgjEAYgTACYQTCCIQR\nCCMQRiC6HZ/gdJJfk1xtMZDa67In+Bg40vMcGtDUCKrqK+CPBrNoID4n0OwiSLKSZC3J2v3792e1\nWTUwswgmD1Kxc+fOWW1WDfhwoE4vET8FvgFeTXInybv9j6WWuhyp5HiLQTQcHw5kBDICYQTCCIQR\nCCMQRiCMQBiBMAIBqaqZb3TXrl11+PDhmW/3SSwtDX9yltXV1aFHoKoy7TbuCWQEMgJhBMIIhBEI\nIxBGIIxAGIEwAmEEotsKpD1JvkxyPcm1JO+1GEztdDnU/SPgg6q6kmQH8F2Si1V1vefZ1EiXg1T8\nUlVXNr7/E7gBDP9/Ws3ME530IskYeA349l9+tgKsAGzbtm0Go6mVzk8MkzwPfA68X1X/OKXH5PEJ\ntm7dOssZ1bNOESQZ8TiAT6rqi35HUmtdXh0E+Ai4UVUf9j+SWuuyJ3gdeAd4M8n3G19v9zyXGupy\nkIqvgakfVtSzy3cMZQQyAmEEwgiEEQgjEEYgjEAYgTAC0dNBKpL8Bvz8FJt4Afh9RuNs5hlerqoX\np92olwieVpK1qjroDG1m8OFARqD5jeDU0AOwiWaYy+cEamte9wRqaK4iSHIkyc0k60lODjTDoOeG\nHmTZX1XNxRewAPwEvAJsAX4A9g8wxxvAAeDqQL+Hl4ADG9/vAH7s+/cwT3uCZWC9qm5V1UPgLHC0\n9RA18Lmha4Blf/MUwRJwe+LyHTb5msf/WvY3S/MUgSZMW/Y3S/MUwV1gz8Tl3RvXbTqtl/3NUwSX\ngX1J9ibZAhwDzg08U3NDLPubmwiq6hFwArjA4ydDn1XVtdZzzMG5oZsv+/MdQ83PnkDDMQIZgYxA\nGIEwAmEEwggE/AVpzG3pSuJVEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20083410f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 120.  160.   90.]\n",
      " [ 240.  280.  150.]\n",
      " [ 150.  170.   90.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAACFCAYAAAB8MZtGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDVJREFUeJzt3c+LVXUch/Hn3cxVxASFWsQoXQMJ3CU6myCklbVxq4tW\nwayEgjb+Fe1mIyQhRBLUwoUgLpIIIpykwB8YkxAqQWWI7UT4tHAWN4ruEe/5nmvzvGBg7p3LuR+G\nZ879Mfd7TqoKbW7PDT2AhmcEMgIZgTACYQTCCIQRCCMQsNjLRhcXazQa9bHpzrZv3z7o/QPcu3dv\n6BGoqky7TS8RjEYjxuNxH5vubHl5edD7Bzhz5szQI3Tiw4GMQEYgjEAYgTACYQTCCIQRCCMQRiA6\nRpDkSJKbSdaTnOx7KLU1NYIkC8Aq8BawHzieZH/fg6mdLnuCZWC9qm5V1UPgLHC037HUUpcIloDb\nE5fvbFyn/4mZfZ4gyQqwArC42MvHFNSTLnuCu8Ceicu7N677m6o6VVUHq+qgETxbukRwGdiXZG+S\nLcAx4Fy/Y6mlqX+yVfUoyQngArAAnK6qa71PpmY67ber6jxwvudZNBDfMZQRyAiEEQgjEEYgjEAY\ngTACYQTCCERPxycYj8eDr80/dOjQoPcP8ODBg0Hv/9KlS51u555ARiAjEEYgjEAYgTACYQTCCIQR\nCCMQRiC6HZ/gdJJfk1xtMZDa67In+Bg40vMcGtDUCKrqK+CPBrNoID4n0OwiSLKSZC3J2v3792e1\nWTUwswgmD1Kxc+fOWW1WDfhwoE4vET8FvgFeTXInybv9j6WWuhyp5HiLQTQcHw5kBDICYQTCCIQR\nCCMQRiCMQBiBMAIBqaqZb3TXrl11+PDhmW/3SSwtDX9yltXV1aFHoKoy7TbuCWQEMgJhBMIIhBEI\nIxBGIIxAGIEwAmEEotsKpD1JvkxyPcm1JO+1GEztdDnU/SPgg6q6kmQH8F2Si1V1vefZ1EiXg1T8\nUlVXNr7/E7gBDP9/Ws3ME530IskYeA349l9+tgKsAGzbtm0Go6mVzk8MkzwPfA68X1X/OKXH5PEJ\ntm7dOssZ1bNOESQZ8TiAT6rqi35HUmtdXh0E+Ai4UVUf9j+SWuuyJ3gdeAd4M8n3G19v9zyXGupy\nkIqvgakfVtSzy3cMZQQyAmEEwgiEEQgjEEYgjEAYgTAC0dNBKpL8Bvz8FJt4Afh9RuNs5hlerqoX\np92olwieVpK1qjroDG1m8OFARqD5jeDU0AOwiWaYy+cEamte9wRqaK4iSHIkyc0k60lODjTDoOeG\nHmTZX1XNxRewAPwEvAJsAX4A9g8wxxvAAeDqQL+Hl4ADG9/vAH7s+/cwT3uCZWC9qm5V1UPgLHC0\n9RA18Lmha4Blf/MUwRJwe+LyHTb5msf/WvY3S/MUgSZMW/Y3S/MUwV1gz8Tl3RvXbTqtl/3NUwSX\ngX1J9ibZAhwDzg08U3NDLPubmwiq6hFwArjA4ydDn1XVtdZzzMG5oZsv+/MdQ83PnkDDMQIZgYxA\nGIEwAmEEwggE/AVpzG3pSuJVEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200834573c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAACFCAYAAAB8MZtGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABElJREFUeJzt3U+IlHUcx/H3J21PKSzWYRmlDCTwlixegg6drIse9bBe\ngj0JBV0Er567dRGSLlGEdfAgSIcggkgnKfAPxqaGK0EtKYYXEb4d3MNE0T7iPL9naN8vWNiZfXie\nL7tvnnlmdp5nUlVoc3tm6AE0PCOQEcgIhBEIIxBGIIxAGIGArX2sdH5+vkajUR+r7uzBgweDbh9g\nx44dg27/1q1brK2tZaPleolgNBpx5syZPlbd2YULFwbdPsDRo0cH3f7i4mKn5Xw4kBHICIQRCCMQ\nRiCMQBiBMAJhBMIIRMcIkhxIcj3JSpLjfQ+ltjaMIMkW4APgTWAvcCTJ3r4HUztd9gT7gZWqulFV\nD4FPgYP9jqWWukQwAm5P3F5dv0//E1M7MEyynGScZHz37t1prVYNdIngDrBr4vbO9fv+pqpOVdVi\nVS3Oz89Paz410CWCi8CeJLuTzAGHgbP9jqWWNnx7WVU9SnIMOA9sAU5X1ZXeJ1Mznd5jWFXngHM9\nz6KB+IqhjEBGIIxAGIEwAmEEwgiEEQgjEEYgero+wc2bN1laWupj1Z2Nx+NBtw+wffv2Qbd/7969\nTsu5J5ARyAiEEQgjEEYgjEAYgTACYQTCCIQRiG7XJzid5Lckl1sMpPa67Ak+Ag70PIcGtGEEVfU1\n8EeDWTQQjwk0vTeVJFkGlgHm5uamtVo1MLU9weRFKrZu7eUNS+qJDwfq9BTxE+Bb4JUkq0ne7n8s\ntdTlSiVHWgyi4fhwICOQEQgjEEYgjEAYgTACYQTCCIQRiJ4uUrGwsMCJEyf6WHVnq6urg24f4NCh\nQ4Nu/+TJk52Wc08gI5ARCCMQRiCMQBiBMAJhBMIIhBEIIxDdzkDaleSrJFeTXEnyTovB1E6X/yI+\nAt6rqktJtgHfJ/myqq72PJsa6XKRil+r6tL6938C14BR34OpnSc6JkjyEvAq8N2//Gw5yTjJ+P79\n+9OZTk10jiDJc8DnwLtV9Y+/8uT1CYb+xA89mU4RJHmWxwF8XFVf9DuSWuvy7CDAh8C1qnq//5HU\nWpc9wWvAEvBGkh/Wv97qeS411OUiFd8AaTCLBuIrhjICGYEwAmEEwgiEEQgjEEYgjEAYgYBU1fRX\nmvwO/PIUq3geWJvSOJt5hher6oWNFuolgqeVZFxVi87QZgYfDmQEmt0ITg09AJtohpk8JlBbs7on\nUEMzFUGSA0muJ1lJcnygGQb9bOhBTvurqpn4ArYAPwMvA3PAj8DeAeZ4HdgHXB7o97AA7Fv/fhvw\nU9+/h1naE+wHVqrqRlU9BD4FDrYeogb+bOga4LS/WYpgBNyeuL3KJj/n8b9O+5umWYpAEzY67W+a\nZimCO8Cuids71+/bdFqf9jdLEVwE9iTZnWQOOAycHXim5oY47W9mIqiqR8Ax4DyPD4Y+q6orreeY\ngc+Gbn7an68Yanb2BBqOEcgIZATCCIQRCCMQRiDgLyuadmhm6bPcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200834c85f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"imag \\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "#Filter\n",
    "weight = tf.constant([[[[1., 10., -1]], [[1., 10., -1]]],\n",
    "                      [[[1., 10., -1]], [[1., 10., -1]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX Pooling\n",
    "\n",
    "- Filter 된 이미지를 적당한 크기로 (아래에서는 2X2크기) 안에 있는 값중 가장 큰값으로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[ 4.]\n",
      "   [ 3.]]\n",
      "\n",
      "  [[ 2.]\n",
      "   [ 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4], [3]],\n",
    "                   [[2], [1]]]], dtype = np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize = [1, 2, 2, 1], strides = [1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUXwFGhz+pWT5yuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2008080de48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = mnist.test.images[0].reshape(28, 28)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter로 나오는 conv2d의 크기는 \n",
    "- padding이 'valid'일떄는 (N- F)/strides + 1\n",
    "- padding이 'SAME'일때는 N/stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_3:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABGxJREFUeJztnc9LZWUYxz9PxixGFJoKjYooUEFwIUQLETcVTIFMK2lW\nLUZctVQS+gdmLeZCcJgJZAJXDW4i3bRpkSJpBuYUDE5MzYSICIJ6fVrc6+B7nes5nnPuee71Ph+4\nnPt9fY/vw9eH98fxPbyiqjg2vGQdQCPj5hvi5hvi5hvi5hvi5hvi5hvi5huSynwRuS4iGyLyUETG\nswqqYVDVRB+gCfgTeA+4AvwKdEfcow3yeRbHw5dT/N0+AB6q6l8AIvIdcAP4/bybmpqaUjRZHxQK\nhUdx6qXpdt4Etk7px6WyABEZEZElEVlK0dalJE3mx0JVp4FpABHxp3inSJP5fwNvn9JvlcqcmKQx\n/xegQ0TeFZErwOfAg2zCagwSdzuqeiQiXwI/UJz53FHV9cwiawAkz3+miIg2yGxnWVXfj6rnK1xD\n3HxD3HxD3HxDqr7IugiFQiHQs7OzZ+p0dnYGem1tLdArKyupYlhcXDxTtrGxkep3VsIz3xA33xA3\n3xA335CaWuG2trYGuqOj40yd4+PjQHd1dZ17T3t7e6DLB/X+/v5A7+3tnWlzYGCgQsQvxle4dYCb\nb4ibb0hNLbJ2d3cDvby8HHnP6upqoJubmwN9cHAQ6PIxZ2JiItDr6/k9FffMN8TNN8TNN6Sm+vwk\nlM/by8cNEQn02NhYoFtaWgI9NzeXYXTn45lviJtviJtvSN33+Relr68v0AsLC4He2toiLzzzDXHz\nDXHzDbl0fX7UvH5nZyfQMzMzVY+pEp75hrj5hrj5hly6Pn9wcDDQQ0NDgZ6cnAz0/v5+1WOqhGe+\nIW6+IZHmi8gdEXkqIr+dKrsmIj+KyGbp+kp1w7ycxOnz7wKTwLenysaBRVW9XXrzfBz4Kvvwoinf\n61P+7GZ+fj7QL9p8a0Vk5qvqT8B2WfEN4F7p+z3gs4zjagiSznbaVPVJ6fs/QFuliiIyAowkbOdS\nk3qqqap63svN/hJ0ZZLOdv4VkTcASten2YXUOCTN/AfAF8Dt0vX7zCKKoPzB2fDwcKBHR0cD3dPT\nE+jDw8PqBJaAOFPN+8DPQJeIPBaRWxRN/1hENoGPStq5IJGZr6o3K/zow4xjaTh8hWtI3T1YOzo6\nCnRvb2+gp6amAr29Xb5EqR088w1x8w1x8w2pqRfi4nD16tVAl48BbW3hk448N0Gd4C/E1QFuviFu\nviF59/nPgEfAa8B/uTWcjDQxvqOqr0dVytX8542KLMUZkCzJI0bvdgxx8w2xMn/aqN2LUPUYTfp8\np4h3O4bkan6tnjRhtTEsN/NFpAn4BvgE6AZuikh3Xu1HcBe4XlZ2sjGsA1gs6UzJM/OfnzShqgfA\nyUkT5lhtDMvT/FgnTdQQsTeGJcUH3BhocUqY+bQwT/Pr7aSJqm8My9P8ejtp4mRjGFRrY1jSc7IS\nnq31KfAHxfO1vs6z7Yi47gNPgEOKY9Et4FWKs5xNYAG4lnW7vsI1xAdcQ9x8Q9x8Q9x8Q9x8Q9x8\nQ9x8Q9x8Q/4H6hW56F9uUUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20080907dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABJNJREFUeJztnb9LZFcUx7/f7OAI2mRikLCJwWIRFBRBtrLTBZNmAzax\nSrEoCCkEiwj5A9xWiCBbLGuaTWHjFmLY2KQwxY5YaILRTWDRuGZdUoioJMJJMc/F+4Zx3rxfZ36c\nD8j4vXP1HL5cz33Xue9diggMHd7TTqCRMfMVMfMVMfMVMfMVMfMVMfMVMfMViWQ+yRGSv5N8SXIm\nrqQaBYZd4ZK8BWAXwD0ABwBeABgTkd9K/Uwmk5FsNhsqXi1xdnb2VkQ+LNcvEyHGXQAvReRPACD5\nA4D7AEqan81m0d3dHSFkbZDP518F6Rel7NwGsH9NH3htDiQnSOZJ5i8vLyOEqz8Sn3BF5JGIDIjI\nQCYT5Q+t/ohi/l8APrmmP/bajIBEMf8FgDskO0k2AfgSwLN40moMQtcBEbkk+TWAHwHcAvBYRH6N\nLbMGIFIRFpEVACsx5dJw2ApXETNfETNfETNfkapa9bS2tjq6r6+vqM/y8rKje3p6HJ3L5SqK6V/4\nHR0dFfU5Pj6u6HcGxUa+Ima+Ima+Ima+IlU14Y6MjDi6vb29qM/09LSj9/f3Hb2+vu7olpYWR5+f\nnzva//nC5ORkUcy2trYSGUfDRr4iZr4iZr4iVVXzl5aWyvaZn593tH9h1tnZ6eiLiwtHNzc339i/\nt7e3KObh4WHZvMJgI18RM18RM1+Rqqr5YTg9PXX01taWo/3X9dvb247u6OhwdH9/f4zZ3YyNfEXM\nfEXMfEVqvuaXY2hoyNGLi4uOHh4edrR/zkgSG/mKmPmKmPmK1F3N91/3z83NOZqko0dHRxPPqRQ2\n8hUx8xUx8xWpu5q/suJump6amnL0+Pi4ozc3NxPPqRQ28hUx8xUpaz7JxyTfkNy+1pYj+Zzknvf6\nfrJp1idBav4TAN8B+P5a2wyANRF56N15PgPgm/jTK4//9tKTkxNH+zfWdnV1JZ5TUMqOfBH5GcA/\nvub7AK7+Q7UI4IuY82oIwl7ttIvIa+/7IwDFW8s8SE4AmACApqamkOHqk8gTrhQe3lDyAQ52E3Rp\nwpr/N8mPAMB7fRNfSo1D2KH4DMBXAB56r8s3d48P/wfiGxsbjvYvogYHBx29s7OTTGIhCHKp+RTA\nLwC6SB6QfICC6fdI7gEY9rRRIWVHvoiMlXhrqES7ERBb4SpSc5cf/hso1tbWHL26uupo/92K1YSN\nfEXMfEXMfEVqrubv7u7e+P7s7KyjFxYWkkwnEjbyFTHzFTHzFQn9RNlQwchjAK8AtAF4m1rgcETJ\n8dMgT5RN1fx3Qcm8iAykHrgC0sjRyo4iZr4iWuY/UopbCYnnqFLzjQJWdhRJ1fxqPWlCa2NYauZ7\nJ03MA/gMQDeAMZLVcpLBEwAjvrarjWF3AKx5OlbSHPnvTpoQkX8BXJ00oY7WxrA0zQ900kQVEXhj\nWFhswg1AuY1hYUnT/Fo7aSLxjWFpml9rJ01cbQwDktoYJiKpfQH4HIWztf4A8G2ascvk9RTAawD/\noTAXPQDwAQpXOXsAfgKQizuurXAVsQlXETNfETNfETNfETNfETNfETNfETNfkf8Bc+4jYTGFpW4A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200835130b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABINJREFUeJztnU9IXFcUxr/PKTLgCDZtCdIW/4ZKNm6kezGBtAjpsq66\nCHTVjQupUDfusnNhu3ERZ3QxXQmNGAjtgHTTRVy2amsshk5JTWMFV1qV08U8U+/TyYzv35k/5wfy\n5nvzZs7h43rufW/ue5ciAkOHFu0EmhkzXxEzXxEzXxEzXxEzXxEzXxEzX5FQ5pO8Q/JXkk9JTkaV\nVLPAoGe4JFMAfgNwG0ARwBMAYyKyXu4z6XRaMplMoHj1xN7e3ksReafScW+EiPEhgKci8jsAkPwW\nwF0AZc3PZDIYHR0NEbI+yOVyz6o5LkzZeRfAH+d00dvnQPJzkmsk1w4PD0OEazxi73BFZE5EhkRk\nKJ1Oxx2urghj/p8A3j+n3/P2GVUSxvwnAG6Q7CHZCuBTAA+jSas5CNzhisgJyS8APAaQAvBARH6J\nLLMmIMxoByLyCMCjiHJpOuwMVxEzXxEzXxEzX5FQHW7U9PX1ObpQKFw4pqenx9G7u7uhYh4fHzu6\npeVie+zs7AwVoxzW8hUx8xUx8xUx8xWpqQ53Y2PD0dPT0xeOSaVSju7o6HD0ycmJow8ODl77vp/L\nflxaXFx87WeCYi1fETNfETNfkZqq+a2trY6en5+/8nd0d3c7+vT01NFdXV2OnpiYcPT+/v6F77Sa\n34CY+YqY+YrUVM2Pgp2dHUf7J2ktLy87enV11dGzs7NxpHUp1vIVMfMVMfMVabia76etrc3RJB09\nODjo6JmZmdhzOsNaviJmviJmviINV/P91/dXVlYcvbCw4OipqanYcyqHtXxFzHxFzHxF6r7m+8ft\n6+vuLWH9/f2OHhgYcHSxWIwnsSqwlq+Ima9IRfNJPiD5guTP5/ZdI/k9yS1v+2a8aTYm1dT8LICv\nAZwfIE8CKIjIfe/O80kAX0afXmV6e3sdnc1mHe2fhzM+Ph53SlVTseWLyI8A/vHtvgsg573OAfgk\n4ryagqA1/7qIPPde/wXgerkD7Sbo8oTucKX0f132AQ52E3R5gpq/S7ITALzti+hSah6CnmQ9BPAZ\ngPve9rvIMqpAe3u7o5eWlhydz+cd7e+AL5sUpUU1Q808gJ8AfECySPIeSqbfJrkF4JanjStSseWL\nyFiZt0YizqXpsDNcReruwpr/5gb/nYLDw8OOnpubiz2noFjLV8TMV8TMV6Tuav7R0ZGjR0bcQdfm\n5qajt7e3Y88pKNbyFTHzFTHzFQn8RNlAwci/ATwD8DaAl4kFDkaYHLuqeaJsoua/CkquichQ4oGv\nQBI5WtlRxMxXRMv82r3g8j+x56hS840SVnYUSdT8Wl1pQmtiWGLmeytNfAPgIwA3AYyRvJlU/Apk\nAdzx7TubGHYDQMHTkZJky3+10oSI/AvgbKUJdbQmhiVpflUrTdQQVU8MC4p1uFVQaWJYUJI0v95W\nmoh9YliS5tfbShNnE8OAuCaGiUhifwA+RmltrW0AXyUZu0JeeQDPARyj1BfdA/AWSqOcLQA/ALgW\ndVw7w1XEOlxFzHxFzHxFzHxFzHxFzHxFzHxFzHxF/gMB2Cbash4AvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200809b2048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABHhJREFUeJztnc9LXFcUx79fo64ctaNDKLXULoKQreIfYBOY1kUEEZxV\nFxFX3St0pyD5AyyIi5AUJNmaRSCYLOxGIS6TQmvaUaqkTUMRdKOtni7mGbxPJu/N+3VmnPMBmfm+\neeM5frme++7MmbkUERg6tGgn0MyY+YqY+YqY+YqY+YqY+YqY+YqY+YrEMp9kkeQvJN+QnE0qqWaB\nUVe4JK8B+BXAbQB7AF4CKInIz9Wek8vlpFAoRIrXSJTL5fciEviHtsaIMQzgjYj8DgAkHwO4A6Cq\n+YVCAQsLCzFCNgalUmk3zHlxys5nAP64oPe8Yw4kp0lukdw6PDyMEe7qkfqEKyLLIjIkIkO5XC7t\ncA1FHPP3AXx+Qfd5x4yQxDH/JYAbJL8k2Q5gEsCTZNJqDiJPuCLyH8nvADwDcA3AfRF5nVhmTUCc\nqx2IyFMATxPKpemwFa4iZr4iZr4iZr4isSbcpOnp6Qk8Z3/fXUr09vY6Op/P1xTz7OzM0Zubm5fO\n6evrq+l3hsVGviJmviJmviJmviJ1NeHu7rovg6+vr186x//mz9HRkaPL5bKju7u7HX18fOzoqakp\nR6+srFyKOTMzUyXjeNjIV8TMV8TMV6Suan5HR4ejR0dHA59zcnLi6NPT048+3t/f7+iNjQ1H+xdt\naWIjXxEzXxEzX5G6qvlRaG9v/+jj/o6J4eFhRxeLRUcvLS0lk1gIbOQrYuYrYuYr0vA1P4jOzk5H\nz8/PO3piYsLRXV1dqed0jo18Rcx8Rcx8Ra5czW9ra3P04OCgo8fGxhy9vLycek7VsJGviJmviJmv\nyJWr+ePj444eGRlx9OTkpKNbW/UssJGviJmvSKD5JO+TfEfy1YVjeZJrJLe920/STfNqEqbgPQCw\nCODHC8dmAbwQkXveJ89nAaTT3BKAv4l1cXHR0f4+Hn+fjiaBI19EfgLwj+/wHQAPvfsPAYzBqJmo\nNf+6iLz17v8J4Hq1E+1D0NWJPeFKpX+v6hc42IegqxPV/L9IfgoA3u275FJqHqKuMJ4A+BbAPe92\nNbGMAvAvigYGBhw9Nzfn6OnpaUe3tNTP1XWYS81HADYADJDcI3kXFdNvk9wGcMvTRo0EjnwRKVV5\n6KuEc2k66ud/sAlpuBfW/DV/ddWdbtbW1hztf4O8nrCRr4iZr4iZr0jD1fyDgwNH7+zsONr/hng9\nr6pt5Cti5iti5isS+RtlIwUj/wawC6AXwPvMAkcjTo5fhPlG2UzN/xCU3BKRocwD10AWOVrZUcTM\nV0TLfL3u1PCknqNKzTcqWNlRJFPz63WnCa3GsMzM93aa+AHA1wBuAiiRvJlV/AAeACj6jp03ht0A\n8MLTiZLlyP+w04SInAA432lCHa3GsCzND7XTRB0RujEsKjbhhiCoMSwqWZrfaDtNpN4YlqX5jbbT\nxHljGJBWY5iIZPYD4BtU9tb6DcD3WcYOyOsRgLcA/kVlLroLoAeVq5xtAM8B5JOOaytcRWzCVcTM\nV8TMV8TMV8TMV8TMV8TMV8TMV+R/t2wYT1V4BHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20083599e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABcCAYAAAAI2GlbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABI9JREFUeJztnb9LZFcUx78nqwF/Dm4iOzEJIcISWLGTYCkmg5M0mzJW\nKQasUthFyB/gFoJNtlFY1yCsjUW2WInJFtpYjGUS0NkERMOaVSMWWkTlpJg3i+fp+N68X2fezvmA\nPL/P65zDl8u57867711iZhg6vKWdQCNj5iti5iti5iti5iti5iti5iti5isSynwiyhPRJhG9IKKJ\nqJJqFCjoDJeIbgHYApADsAugCGCUmf+o9j+ZTIaz2WygeGlia2vrgJm7vdo1hYjxKYAXzPwXABDR\nIoD7AKqan81mMTMzEyJkOhgaGtr20y5M2XkfwM4lveucExDRGBFtENHG8fFxiHBvHrEPuMw8w8wD\nzDyQyWTiDpcqwpj/N4APL+kPnHOGT8KYXwRwl4g+JqK3AXwN4Gk0aTUGgQdcZj4nom8B/AzgFoBH\nzPx7ZJk1AGGudsDMzwA8iyiXhsNmuIqY+YqY+YqY+YqEGnCjZnZ2VuhCoXCljXui1tPTI/TBwUFN\nMVtbW4Xu7e290mZ1dbWmz/SL9XxFzHxFzHxFzHxF6mrA7e/vF3pubu5Km1KpJPTOzo7Q7e3tQnd0\ndAjd3S3vcSwvLwt9dHTkL9kIsJ6viJmviJmvSF3V/MHBwRv1dZycnAh9enoq9NnZmdDz8/NCr62t\nCT09PX0lxvDwsGceQbCer4iZr4iZr0hd1fwgtLW13agPDw+FPj8/F7qrq0vovr6+CLO7Gev5ipj5\nipj5iqS+5nvhvkEzPj4u9OLiotC5XC72nCpYz1fEzFfEzFfkjav5e3t7Qre0tAjtvkHe1KRngfV8\nRcx8Rcx8RVJf890P9E1OTgo9NTUl9MLCgtAjIyPxJOYD6/mKmPmKeJpPRI+I6BUR/Xbp3G0i+oWI\nSs6x66bPMK7HT81/DOAHAD9eOjcB4DkzP3CePJ8A8F306XmztLQktLvmr6+vCx3X/dggePZ8Zl4D\n8K/r9H0AlTvR8wC+ijivhiBozb/DzC+d3/cA3KnW0B6Crk7oAZfL13pVX+BgD0FXJ6j5/xDRewDg\nHF9Fl1LjEHSS9RTANwAeOMefIsvIA/eTJ5ubm0KPjY0JfXFxIXRzc3M8iQXAz6XmEwDrAD4hol0i\nKqBseo6ISgA+d7RRI549n5lHq/zps4hzaThshqtI6r5YW1lZEbqzs1Po/f19od0LZesJ6/mKmPmK\nmPmKpK7m5/N5oYvFotDb2/Ldctc9UV4vWM9XxMxXxMxXJPAbZQMFI9oHsA3gXQC1vR4kecLk+JGf\nN8omav7roEQbzDyQeOAaSCJHKzuKmPmKaJmfhrdZx56jSs03yljZUSRR8+t1pwmthWGJme/sNPEQ\nwBcA7gEYJaJ7ScX34DGAvOtcZWHYXQDPHR0pSfb81ztNMPN/ACo7TaijtTAsSfN97TRRR/heGBYU\nG3B94LUwLChJmp+2nSZiXxiWpPlp22misjAMiGthGDMn9gPgS5T31voTwPdJxvbI6wmAlwDOUB6L\nCgDeQfkqpwTgVwC3o45rM1xFbMBVxMxXxMxXxMxXxMxXxMxXxMxXxMxX5H9OgSlB6f26kwAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200868a0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "img = mnist.test.images[0]\n",
    "# 28 X 28의 1색깔 -1은 알아서 계산하라는 뜻\n",
    "img = img.reshape(-1, 28, 28, 1)\n",
    "# 3*3의 filter 5개 이용\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev = 0.01))\n",
    "\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(conv2d)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(one_img.reshape(14, 14), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conv2d 의 크기 14 * 14 \n",
    "- ksize 2*2 \n",
    "- strides 2\n",
    "- 14/2 = 7  ---> 7*7 크기의 아웃풋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABcCAYAAADqBHIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA0xJREFUeJztnD1PVEEYhc/hY0NiLEjULdQYTGy0hFjZWGikskQ7Khr8\nAf4SCgpLYwdYgEYrWzDR+BE1SNa4FKgJhQmFwbwWLHGN5M6wd8+y7J4n2cDemcu8eTK8szM7dxgR\nMDoGjjqAXseCxViwGAsWY8FiLFiMBYuxYDEWLGZI8UdJ9sX0MCKYqpPVg0neIvmR5DrJ++VD6yMi\novAFYBDAZwAXAVQAvAZwOXFP9MMr5S4isnrwVQDrEbEREb8APAJwO+M+g7wUcRbA16b39ca1fyA5\nQ3KN5Fq7gusF2jbIRcQ8gHmgfwa5HHJ68CaA803vzzWumRwyBrkhABsAxvB3kLviQS5vkEumiIjY\nJXkPwFPsfaJ4EBHvUvcVMT09nayzs7NTWF6r1QrLBwaK/zlHR0eTMaysrCTrpMjKwRGxDGC5dGt9\niKfKYixYjAWLsWAxFizGgsVYsBjJgnuK4eHhZJ2RkZHC8vHx8cLyubm5wvKpqalkDO3APViMBYux\nYDEWLMaCxViwGAsWQ8UjBN3wndzW1lZhebVaLd1G2zaemNaxYDEWLMaCxViwGAsWY8FijmQ9uB1s\nb28Xli8uLnYokmLcg8VYsBgLFmPBYixYjAWLsWAxXbsePDk5WVi+tLRUWF6pVMqGkCRnPThrokGy\nBuAngN8AdiNiolxo/cNhZnLXI+KHLJIexTlYTK7gAPCc5EuSMwdV8IOIB5ObIq5FxCbJMwCekfwQ\nES+aK/hBxIPJ6sERsdn4+Q3AAvaeXzYZJAWTPEHy5P7vAG4CeKsOrFfISRFVAAsk9+s/jIgn0qh6\niK6daKQmEvV6vbB8dna2bAhJvPGkC7BgMRYsxoLFWLAYCxZjwWJUn4O/A/jSdOkUgG5f6jxsjBci\n4nSqkkTwf42Qa92+SK+K0SlCjAWL6ZTg+Q61UwZJjB3Jwf2MU4QYqeDjcu4wyRrJNyRftfs7RVmK\nIDkI4BOAG9g7sXUVwN2IeC9psASNfR8Tim0Jyh7sc4ehFZx17nCXkNyW0CrH9hmNNpPcltAqyh58\nbM4dVm5LUApeBXCJ5BjJCoA7AB4L22sJ9bYEWYpQnDssQrotwTM5MZ7JibFgMRYsxoLFWLAYCxZj\nwWIsWMwfmtD69Z43dHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20086918198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABcCAYAAADqBHIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA11JREFUeJztnE9LVFEYxp8nRRfRrj9IRRgEWkgbaSFtWhSz0bb1BVxI\nH6CFn8OFi5bRTgiRsnDRtgmKTCpNjHIztmsXxtvCiUaSe44z9xnHmecHwzj3nDv35ceZc849vvcw\nImB0nDjqALodCxZjwWIsWIwFi7FgMRYsxoLFWLCYfsWXkuyJ28OIYKpOVgsmWSH5ieQGyYeth9ZD\nREThC0AfgC8ALgMYAPAOwNXEOdELr5S7iMhqwTcAbETEZkT8AvAEwN2M8wzyuojzAL41fP5eP7YP\nktMkqySrZQXXDZQ2yEXEPIB5oHcGuRxyWvA2gIsNny/Uj5kcMga5fgCbAIbxb5C75kEub5BLdhER\nsUvyAYDn2JtRPIqID6nzipidnU3WGR0dLSxfX19vJQQsLi4m61SrrQ8nWX1wRCwBWGr5aj2Ib5XF\nWLAYCxZjwWIsWIwFi7FgMVSkTqXWIgYHB5PfMTk5WVg+NDRUWD4yMlJYPjMzk4yBLF5PL23B3TSP\nBYuxYDEWLMaCxViwGAsWcyTz4DKYmJgoLF9ZWSksn5qaSl5jeXm5sNzz4A7AgsVYsBgLFmPBYixY\njAWLkSRgt4PUevDOzk5heWqOWxZuwWIsWIwFi7FgMRYsxoLFWLCYjp0HVyqVwvK5ubnC8rGxsTLD\naZoswSS3APwE8BvAbkSMK4PqJg7Tgm9FxA9ZJF2K+2AxuYIDwEuSb0hOH1TBDyIeTG4XcTMitkme\nBfCC5MeIeNVYwQ8iHkxWC46I7fp7DcAC9p5fNhkkBZM8SfLU378B3AGwqg6sW8jpIs4BWKjnyvYD\neBwRz6RRdRE5T3puArjehlj2sba2Vli+ulr8I6rVamWG0zSepomxYDEWLMaCxViwGAsWY8FiVAnY\nOwC+Nhw6DaDTlzoPG+OliDiTqiQR/N9FyGqnL9KrYnQXIcaCxbRL8HybrtMKkhjb0gf3Mu4ixEgF\nH5d9h0lukXxP8m3Z/1OUdREk+wB8BnAbezu2vgZwPyKKF3qPgHrex7giLUHZgr3vMLSCs/Yd7hCS\naQnN0rG5aW0mmZbQLMoWfGz2HVamJSgFvwZwheQwyQEA9wA8FV6vKdRpCbIuQrHvsAhpWoLv5MT4\nTk6MBYuxYDEWLMaCxViwGAsWY8Fi/gCgffy4lWH3wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20086993518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABcCAYAAADqBHIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA0VJREFUeJztnL1rU1EYxp/HilAkm9FBJbXg0sUlOLk4KDq5pv9AJ8dC\npX9AcXVwCeJo3QoORdHJtSkV/ECllBTtYrqlk1Reh6aQ0nLvaXOfNEmf35KPczjn5cfhcO7lPS8j\nAkbHudMOYNSxYDEWLMaCxViwGAsWY8FiLFiMBYs5rxi0VCpFuVxWDD0wtFottNtt5vVLEkzyAYBn\nAMYAvIiIp1n9y+UyFhYWkgIdVubn55P65W4RJMcAPAfwEMAUgGmSUz1Fd4ZI2YNvA1iPiI2I+Avg\nNYBH2rBGhxTBVwH86vr9u/PfAUjOkGyQbLTb7aLiG3oKO0VERD0iqhFRLZVKRQ079KQI3gJwvev3\ntc5/JoEUwSsAbpK8QfICgBqAN9qwRofcY1pE7JJ8DOAd9o5pLyPiqzyyESHpHBwRywCWxbGMJH5U\nFmPBYixYjAWLsWAxFizGgsVIXrjnMTExkdtne3s7s318fDyzfW5uLrN9dnY2N4Yi8AoWY8FiLFiM\nBYuxYDEWLMaCxZzKObjZbPY8xs7OTmb76upqz3MUgVewGAsWY8FiLFiMBYuxYDEWLOZUzsFFsLm5\nmdm+uLjYp0iy8QoWY8FiLFiMBYuxYDEWLMaCxQztOXhtbS2zvVKp9CmSbFIvIjYBtAH8A7AbEVVl\nUKPEcVbw3YjITrcxh/AeLCZVcAD4QHKV5MxRHXwR8WhSt4g7EbFF8jKA9yS/R8TH7g4RUQdQB4DJ\nyUkXY+uQtIIjYqvz+QfAEvbuL5sEUm7bXyRZ2v8O4D6AL+rARoWULeIKgCWS+/1fRcRbaVQjRMpN\nzw0At/oQywFqtVq/p5TgY5oYCxZjwWIsWIwFi7FgMRYshooa7iRbALozQy4BGPRXnceNsRIRueUN\nJYIPTUI2Bv0lvSpGbxFiLFhMvwTX+zRPL0hi7MsefJbxFiFGKpjkA5I/SK6TfKKcqxdINkl+JvmJ\nZKPQsVVbRKfu8E8A97BXsXUFwHREfJNM2AOdvI+qIi1BuYJddxhawUl1hweE3LSEkzK0uWkFk5uW\ncFKUK3ho6g4r0xKUgoei7rA6LUG2RQxR3WFpWoKf5MT4SU6MBYuxYDEWLMaCxViwGAsWY8Fi/gOp\nWvNmFVSuhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200869ff7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABcCAYAAADqBHIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAzxJREFUeJztnD9rFFEUxc8xIY3Y+adwRbJgsxYWCVY2FoqdXdAvkMo6\n+A3yHVIIaUSSImARFK1skwVFDSpxiWga3c5OYq5FVtyYMPOyM2cy2T0/WDY7b2bn8uNx387LfY8R\nAaPj1HEHMOxYsBgLFmPBYixYjAWLsWAxFizGgsWMK76U5Eg8HkYE885J6sEk75D8SHKT5MPioY0Q\nEZH5AjAG4DOAJoAJAG8AtHKuiVF45bmLiKQefB3AZkR0IuIXgCcA7iZcZ5CWIi4C+Nr3+Vvv2D5I\nzpJcJ7leVnDDQGmDXEQsAFgARmeQSyGlB28DuNT3udE7ZlJIGOTGAXQATOLfIHfVg1zaIJebIiJi\nh+QDAM+x94viUUS8z7sui06nk3tOu93ObF9aWioSApaXlwtdn0pSDo6IVQCr4liGEj8qi7FgMRYs\nxoLFWLAYCxZjwWKoKJ0qYy6i1Wpltjcajcz2+fn5zPapqakjx/Q/pU24m8GxYDEWLMaCxViwGAsW\nY8FiJIUnZbCxsZHZPjc3l9nebDbLDGdg3IPFWLAYCxZjwWIsWIwFi7FgMbWdDyazp1p3d3cLXV8G\nng+uARYsxoLFWLAYCxZjwWIsWExt54O73W5m+8zMTEWRFCNJMMktAD8B/AawExHTyqCGiaP04JsR\nkd2tzAGcg8WkCg4AL0m2Sc4edoIXIh5Oaoq4ERHbJM8DeEHyQ0S86j/BCxEPJ6kHR8R27/07gBXs\nrV82CeQKJnma5Jm/fwO4DeCdOrBhISVFXACw0ptfHQfwOCKeSaMaIlJWenYAXKsgln0sLi5mtle1\nUrMo/pkmxoLFWLAYCxZjwWIsWIwFi1EVnvwA8KXv0FkAdZ/qPGqMlyPiXN5JEsEHbkKu132SXhWj\nU4QYCxZTleCFiu5TBEmMleTgUcYpQoxU8EnZd5jkFsm3JF+X/T9FWYogOQbgE4Bb2NuxdQ3A/YjI\nXmF4DPTqPqYVZQnKHux9h6EVnLTvcE3ILUsYlNrWplVMblnCoCh78InZd1hZlqAUvAbgCslJkhMA\n7gF4KrzfQKjLEmQpQrHvsAhpWYKf5MT4SU6MBYuxYDEWLMaCxViwGAsWY8Fi/gAy9fWVpNSoBgAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2008094f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABcCAYAAADqBHIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA1NJREFUeJztnLFLVVEcx7/fXgSP6E2VQ0U0tDiYw6OppaGwybW3ODoF\nDi79CTk4NLRItAgZLkKDFDW1qhCUUSFilEs1vYYHafwafIKS3Xv03e/Td/1+Fn33HO758uFwOPfy\nu4cRAaPjxGEHKDsWLMaCxViwGAsWY8FiLFiMBYuxYDEnFTetVqtRq9UUtz4yNJtNtFot5vVLEkxy\nCMBDABUAjyPiQVb/Wq2GRqORFLRXmZmZSeqXu0SQrAB4BOAOgH4ADZL9HaU7RqSswdcBrETEakT8\nBvAMwLA2VnlIEXwBwNcdv7+1r+2C5CjJRZKLrVarqHw9T2G7iIiYioh6RNSr1WpRt+15UgSvA7i0\n4/fF9jWTQIrgBQBXSV4heQrAXQDPtbHKQ+42LSI2Sd4D8BJb27QnEbEsT1YSkvbBETEPYF6cpZT4\nUVmMBYuxYDEWLMaCxViwGAsWI3nhnsfk5GRun0qlktk+PT2d2T4yMpLZPjY2lpuhCDyDxViwGAsW\nY8FiLFiMBYuxYDGHsg8eHx+XjzEwMCAfIwXPYDEWLMaCxViwGAsWY8FiLFjMoeyDi2B5Obv2ZXg4\nuwC02WwWGee/eAaLsWAxFizGgsVYsBgLFmPBYnp2Hzw4OJjZvrGx0aUk2aR+iLgG4BeAPwA2I6Ku\nDFUm9jODb0bET1mSkuI1WEyq4ADwmuQSydG9OvhDxL1JXSJuRMQ6yfMAXpH8GBFvdnaIiCkAUwDQ\n19fnw9jaJM3giFhv//0OYA5b3y+bBFK+tj9N8sz2/wBuA3ivDlYWUpaIPgBzJLf7P42IF9JUJSLl\nS89VANe6kGUXExMTme2zs7OZ7UtLS0XGOTDepomxYDEWLMaCxViwGAsWY8FiqDjDneQPAF92XDoL\n4Ki/6txvxssRcS6vk0TwP4OQi0f9Jb0qo5cIMRYspluCp7o0TidIMnZlDT7OeIkQIxVMcojkJ5Ir\nJO8rx+oEkmsk35F8S3Kx0Hurloj2ucOfAdzC1omtCwAaEfFBMmAHtOs+6oqyBOUM9rnD0ApOOnf4\niJBblnBQerY2rWByyxIOinIG98y5w8qyBKXgnjh3WF2WIFsieujcYWlZgp/kxPhJTowFi7FgMRYs\nxoLFWLAYCxZjwWL+Alnn9JWkap3qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x200867f64e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(one_img.reshape(7, 7), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started, It takes times\n",
      "epoch : 1, cost =0.336670278\n",
      "epoch : 2, cost =0.096485238\n",
      "epoch : 3, cost =0.070345327\n",
      "epoch : 4, cost =0.056363511\n",
      "epoch : 5, cost =0.047143751\n",
      "epoch : 6, cost =0.040687996\n",
      "epoch : 7, cost =0.035179751\n",
      "epoch : 8, cost =0.030787914\n",
      "epoch : 9, cost =0.027468251\n",
      "epoch : 10, cost =0.023977257\n",
      "epoch : 11, cost =0.020785034\n",
      "epoch : 12, cost =0.018512354\n",
      "epoch : 13, cost =0.017214839\n",
      "epoch : 14, cost =0.014740563\n",
      "epoch : 15, cost =0.014031536\n",
      "Learning Finished\n",
      "Accuracy :  0.9901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#L1 image shape = (?, 28, 28, 1)\n",
    "# filter 3*3 크리 1color 32개로 진행\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# conv -> (?, 28, 28, 32)\n",
    "# pool -> (?, 14, 14, 32)\n",
    "L1_conv2d = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "L1 = tf.nn.relu(L1_conv2d)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "# L2 image shape = (?, 14, 14, 32)\n",
    "W2= tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "# conv -> (?, 14, 14, 64)\n",
    "# pool -> (?, 7, 7, 64)\n",
    "\n",
    "L2_conv2d = tf.nn.conv2d(L1, W2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "L2 = tf.nn.relu(L2_conv2d)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "# 이것을 Fully connected  layer에 넣기 위해서 reshpae를 통해 펼친다\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "# 그리고 L2를 (?, 3136)으로 reshape\n",
    "\n",
    "# final FC 7*7*64 inputs -> 10 output\n",
    "W3 = tf.get_variable('W33', shape = [7 * 7 * 64, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "\n",
    "predicted = tf.argmax(logits, 1)\n",
    "is_correct = tf.equal(predicted, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, dtype = tf.float32))\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"Learning Started, It takes times\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('epoch : {}, cost ={:.9f}'.format(epoch + 1, avg_cost))\n",
    "    \n",
    "print(\"Learning Finished\")\n",
    "\n",
    "print(\"Accuracy : \", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP CONV in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, cost =0.434584659\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7893d17f5775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch : {}, cost ={:.9f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "#변수\n",
    "learning_rate = 0.001\n",
    "\n",
    "#첫번째 레이어 입력 그림 크기 [-1, 28, 28, 1]\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "#두번째 레어이 입력 그림 크기 [-1, 14, 14, 32]\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize =[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "#세번째 레이어 입력 그림 크기 [-1, 7, 7, 64]\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.01))\n",
    "\n",
    "L3 = tf.nn.conv2d(L2, W3, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "#펼치기\n",
    "L3_flat = tf.reshape(L3, [-1, 4 * 4 * 128])\n",
    "\n",
    "#네번째 레이어 여기서부터는 fully connected layer\n",
    "W4 = tf.get_variable('W44dfsdfg444', shape = [4 * 4 * 128, 625], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "#다섯번째 레이어 (output layer)\n",
    "W5 = tf.get_variable('W555dfsdfg55', shape = [625, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob : 0.7}\n",
    "        c, _= sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('epoch : {}, cost ={:.9f}'.format(epoch + 1, avg_cost))\n",
    "    \n",
    "print(\"Learning Finished\")\n",
    "\n",
    "print(\"Accuracy : \", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 깔끔하게 클래스로 정리해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started\n",
      "Epoch: 0001 cost = 0.000393160\n",
      "Epoch: 0002 cost = 0.000118439\n",
      "Epoch: 0003 cost = 0.000128507\n",
      "Epoch: 0004 cost = 0.000111209\n",
      "Epoch: 0005 cost = 0.000298314\n",
      "Epoch: 0006 cost = 0.000123257\n",
      "Epoch: 0007 cost = 0.000104389\n",
      "Epoch: 0008 cost = 0.000108707\n",
      "Epoch: 0009 cost = 0.000036123\n",
      "Epoch: 0010 cost = 0.000067946\n",
      "Epoch: 0011 cost = 0.000077932\n",
      "Epoch: 0012 cost = 0.000004117\n",
      "Epoch: 0013 cost = 0.000045550\n",
      "Epoch: 0014 cost = 0.000045605\n",
      "Epoch: 0015 cost = 0.000006545\n",
      "Learning Finished!\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_84' with dtype float and shape [?,784]\n\t [[Node: Placeholder_84 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_84', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-7893d17f5775>\", line 1, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, 784])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_84' with dtype float and shape [?,784]\n\t [[Node: Placeholder_84 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_84' with dtype float and shape [?,784]\n\t [[Node: Placeholder_84 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-db023e7f9df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[1;31m# Test model and check accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-db023e7f9df5>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(self, x_test, y_test, keep_prop)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeep_prop\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_84' with dtype float and shape [?,784]\n\t [[Node: Placeholder_84 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_84', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-7893d17f5775>\", line 1, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, 784])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_84' with dtype float and shape [?,784]\n\t [[Node: Placeholder_84 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            #input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28X28X1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            #L1 image shape = (-1, 28, 28 , 1)\n",
    "            #filter 3X3, 32개\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "            L1 = tf.nn.dropout(L1, self.keep_prob)\n",
    "            \n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "            L2 = tf.nn.dropout(L2, self.keep_prob)\n",
    "            L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "            \n",
    "            W3 = tf.get_variable('W333222133', shape = [7 * 7 * 64, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "            b3 = tf.Variable(tf.random_normal([10]))\n",
    "            self.hypothesis = tf.matmul(L2_flat, W3) + b3\n",
    "            \n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.hypothesis, labels = self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(self.cost)\n",
    "            \n",
    "            is_corrrct = tf.equal(tf.argmax(self.hypothesis, 1), tf.argmax(self.Y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop = 1.0):\n",
    "        return self.sess.run(self.hypothesis, feed_dict = {self.X: x_test, self.keep_prob : keep_prop})\n",
    "    \n",
    "    def get_accuracy(self, x_test, y_test, keep_prop = 1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict = {self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "    \n",
    "    def train(self, x_data, y_data, keep_prop = 0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict = {self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "    \n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"Learning Started\")\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n",
    "        avg_cost = c / total_batch\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.381203758\n",
      "Epoch: 0002 cost = 0.092832897\n",
      "Epoch: 0003 cost = 0.070447051\n",
      "Epoch: 0004 cost = 0.056796042\n",
      "Epoch: 0005 cost = 0.049129266\n",
      "Epoch: 0006 cost = 0.046718946\n",
      "Epoch: 0007 cost = 0.041865470\n",
      "Epoch: 0008 cost = 0.038871896\n",
      "Epoch: 0009 cost = 0.036591671\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W123254646514\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W11321654456\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.layers 사용 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "#변수\n",
    "learning_rate = 0.001\n",
    "\n",
    "#첫번째 레이어 입력 그림 크기 [-1, 28, 28, 1]\n",
    "#W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.35))\n",
    "\n",
    "#L1 = tf.nn.conv2d(X_img, W1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "#L1 = tf.nn.relu(L1)\n",
    "#L1 = tf.nn.max_pool(L1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "#L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=X_img, filters = 32, kernel_size=[3, 3], padding ='SAME', activation=tf.nn.relu)\n",
    "pool1 =tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], padding='SAME', strides=2)\n",
    "dropout1 = tf.layers.dropout(inputs=pool1, rate=0.7, training=self.training)\n",
    "\n",
    "#두번째 레어이 입력 그림 크기 [-1, 14, 14, 32]\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.35))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize =[1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "#세번째 레이어 입력 그림 크기 [-1, 7, 7, 64]\n",
    "#W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.35))\n",
    "\n",
    "#L3 = tf.nn.conv2d(L2, W3, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "#L3 = tf.nn.relu(L3)\n",
    "#L3 = tf.nn.max_pool(L3, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "#L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "#펼치기\n",
    "#L3 = tf.reshape(L3, [-1, 4 * 4 * 128])\n",
    "conv3 = tf.layers.conv2d(inputs=L2, filters = 128, kernal_size=[3, 3], padding = 'SAME', activation = tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2,2], padding='SAME', strides=2)\n",
    "dropout3 = tf.layers.dropout(inputs=pool3, rate=0.7, training=self.training)\n",
    "flat = tf.reshape(dropout3, [-1, 128 * 4 *4])\n",
    "\n",
    "#아래에 있는 4번째레이어를 이와같이 매우 간단하게 표현 가능\n",
    "dense4 = tf.layers.dense(input=flat, units=625, activation=tf.nn.relu)\n",
    "dropout4 = tf.layers.dropout(inputs=dense4, rate=0.7, training=self.training)\n",
    "\n",
    "#네번째 레이어 여기서부터는 fully connected layer\n",
    "# = tf.get_variable('W444444444', shape = [4 * 4 * 128, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "#b4 = tf.Variable(tf.random_normal([512]))\n",
    "#L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "#L4 = tf.nn.dropout(L4, keep_prob)\n",
    "\n",
    "\n",
    "#다섯번째 레이어 (output layer)\n",
    "W5 = tf.get_variable('W55555555', shape = [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob : 0.7}\n",
    "        c, _= sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('epoch : {}, cost ={:.9f}'.format(epoch + 1, avg_cost))\n",
    "    \n",
    "print(\"Learning Finished\")\n",
    "\n",
    "print(\"Accuracy : \", sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSAMBLE 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "num_models = 7\n",
    "sess = tf.Session()\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Learning Started')\n",
    "\n",
    "for epoch inrange(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "    print('Epochs: {}, cost = {}'.format(epoch + 1, avg_cost_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emsamble prediction\n",
    "- 다양한 기법 존재 \n",
    "- 여기서는 결과들을 단순히 합하여 argmax로 점수가 가장 높은 것을 결과로 잡는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(mnist.test.images, mnist.test.labels))\n",
    "    o = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "emsemble_correct_prediction tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "emsemble_accuracy = tf.reducemean(tf.cast(emsemble_correct_prediction, tf.float32))\n",
    "print(\"앙상블 정확도 : {}\".format(emsemble_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
